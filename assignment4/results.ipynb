{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4 - AI : \n",
    "---\n",
    "_Author: CHRISTOFOROU Anthony_\\\n",
    "_Due Date: XX-XX-2023_\\\n",
    "_Updated: 29-11-2023_\\\n",
    "_Description: TP4 - AI_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Modules\n",
    "from assignment4.utils import (calculate_entropy, calculate_information_gain, calculate_gini_index)\n",
    "from assignment4.algorithms.decision_trees.id3 import ID3DecisionTree\n",
    "\n",
    "# make figures appear inline\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 8)\n",
    "%matplotlib inline\n",
    "\n",
    "# notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entropy and Information Gain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Depedent Variable Entropy\n",
    "\n",
    "The first step in building a decision tree is to calculate the entropy of the dependent variable. The entropy of the dependent variable is also known as the class entropy.\n",
    "\n",
    "<div class='alert alert-info'>\n",
    "But what is even Entropy?\n",
    "</div>\n",
    "\n",
    "Entropy is a measure of the amount of uncertainty or randomness in data.\n",
    "To calculate the entropy of the dependent variable, we need to determine the frequency of each class in the target variable and then use the entropy formula:\n",
    "\n",
    "$$Entropy(S) = -\\sum_{i=1}^{c}p_i\\log_2(p_i)$$\n",
    "\n",
    "where $p_i$ is the proportion of the number of elements in class $i$ to the number of elements in set $S$.\n",
    "\n",
    "<div class='alert alert-info'>\n",
    "So how do we do this, and how do we now which one is the dependent variable?\n",
    "</div>\n",
    "\n",
    "Let's start by loading the CSV data and find the dependent variable. We we then use the formula and calculate the entropy.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D  E  c\n",
       "0  0  1  3  1  1  0\n",
       "1  0  1  2  1  2  0\n",
       "2  0  0  3  4  0  1\n",
       "3  0  1  1  3  1  0\n",
       "4  0  0  1  3  0  1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'data/data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has five independent variables (A, B, C, D, E) and one dependent variable (c). The next step is to calculate the entropy of the said dependent variable.\n",
    "\n",
    "Let's calculate the entropy of 'c'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculates Entropy: 0.974\n"
     ]
    }
   ],
   "source": [
    "entropy = calculate_entropy(data, 'c')\n",
    "print(f\"Calculates Entropy: {entropy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entropy of the dependent variable `'c'` in the dataset is approximately `0.974`. This value represents the amount of uncertainty or randomness in the distribution of class labels in the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Information Gain after Random Decision Criteria Application "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will calculate the information gain after applying three random decision criteria. For this, we need to:\n",
    "\n",
    "1. Select three random features (criteria) from the independent variables.\n",
    "2. For each feature, split the dataset based on its unique values.\n",
    "3. Calculate the entropy for each split.\n",
    "4. Compute the information gain for each feature.\n",
    "\n",
    "<div class='alert alert-info'>\n",
    "We will select three features randomly from the dataset and calculate their information gain. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information gain for D: 0.167\n",
      "Information gain for B: 0.152\n",
      "Information gain for A: 0.029\n"
     ]
    }
   ],
   "source": [
    "# Select three random features from the independent variables\n",
    "random_features = np.random.choice(['A', 'B', 'C', 'D', 'E'], 3, replace=False)\n",
    "\n",
    "# Calculate the information gain for each of these features\n",
    "information_gains = {feature: calculate_information_gain(data, feature, 'c') for feature in random_features}\n",
    "for feature, gain in information_gains.items():\n",
    "    print(f\"Information gain for {feature}: {gain:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "These values indicate how much each feature reduces the uncertainty about the class labels. A higher information gain implies a greater reduction in uncertainty.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Gini Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will calculate the Gini index for the same three features. The Gini index is calculated as:\n",
    "\n",
    "$$Gini(S) = 1 - \\sum_{i=1}^{c}p_i^2$$\n",
    "\n",
    "where $p_i$ is the proportion of the number of elements in class $i$ to the number of elements in set $S$.\n",
    "\n",
    "Let's proceed with calculating the Gini index for the random features,\n",
    "the Gini index should be a value between 0 and 1, where 0 indicates perfect purity (all elements in a subset belong to the same class) and 1 indicates maximal impurity (elements are evenly distributed across different classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini index for D: 0.377\n",
      "Gini index for B: 0.384\n",
      "Gini index for A: 0.463\n"
     ]
    }
   ],
   "source": [
    "gini_indices = {feature: calculate_gini_index(data, feature, 'c') for feature in random_features}\n",
    "for feature, gain in gini_indices.items():\n",
    "    print(f\"Gini index for {feature}: {gain:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gini index measures the impurity of a dataset after a split. A lower Gini index indicates a better split, as it implies a higher purity of the subsets created by the split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Best Decision Criteria\n",
    "\n",
    "After calculating for the three random features multiple times, we can see:\n",
    "- The Information Gain is always the highest for the feature `'E'`, suggesting it is the most informative for predicting the dependent variable `'c'`.\n",
    "- That the Gini index is always the lowest for the feature `'E'`. It appears to be the most effective at reducing impurity.\n",
    "\n",
    "Therefore, according to both the information gain and the Gini index, feature E is the preferable criterion for decision-making in this scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ID3 Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. ID3 Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: E\n",
      "    ├── Value: 0\n",
      "        Node: C\n",
      "            ├── Value: 0.0\n",
      "                └── Leaf: 0.0\n",
      "            ├── Value: 1.0\n",
      "                └── Leaf: 1.0\n",
      "            ├── Value: 2.0\n",
      "                Node: A\n",
      "                    ├── Value: 0.0\n",
      "                        └── Leaf: 1.0\n",
      "                    └── Value: 1.0\n",
      "                        Node: B\n",
      "                            ├── Value: 0.0\n",
      "                                └── Leaf: 0.0\n",
      "                            └── Value: 1.0\n",
      "                                └── Leaf: 1.0\n",
      "            └── Value: 3.0\n",
      "                └── Leaf: 1.0\n",
      "    ├── Value: 1\n",
      "        Node: D\n",
      "            ├── Value: 0.0\n",
      "                Node: A\n",
      "                    ├── Value: 1.0\n",
      "                        └── Leaf: 0.0\n",
      "                    └── Value: 2.0\n",
      "                        └── Leaf: 1.0\n",
      "            ├── Value: 1.0\n",
      "                Node: B\n",
      "                    ├── Value: 0.0\n",
      "                        Node: A\n",
      "                            ├── Value: 0.0\n",
      "                                └── Leaf: 0.0\n",
      "                            └── Value: 2.0\n",
      "                                └── Leaf: 1.0\n",
      "                    ├── Value: 1.0\n",
      "                        └── Leaf: 0.0\n",
      "                    └── Value: 2.0\n",
      "                        Node: C\n",
      "                            ├── Value: 0.0\n",
      "                                └── Leaf: 1.0\n",
      "                            └── Value: 1.0\n",
      "                                └── Leaf: 0.0\n",
      "            ├── Value: 2.0\n",
      "                Node: A\n",
      "                    ├── Value: 0.0\n",
      "                        └── Leaf: 0.0\n",
      "                    └── Value: 2.0\n",
      "                        Node: B\n",
      "                            ├── Value: 0.0\n",
      "                                └── Leaf: 1.0\n",
      "                            └── Value: 1.0\n",
      "                                └── Leaf: 0.0\n",
      "            ├── Value: 3.0\n",
      "                └── Leaf: 0.0\n",
      "            └── Value: 4.0\n",
      "                └── Leaf: 0.0\n",
      "    └── Value: 2\n",
      "        Node: D\n",
      "            ├── Value: 0.0\n",
      "                └── Leaf: 1.0\n",
      "            ├── Value: 1.0\n",
      "                Node: B\n",
      "                    ├── Value: 0.0\n",
      "                        └── Leaf: 1.0\n",
      "                    ├── Value: 1.0\n",
      "                        └── Leaf: 0.0\n",
      "                    └── Value: 2.0\n",
      "                        Node: C\n",
      "                            ├── Value: 0.0\n",
      "                                └── Leaf: 1.0\n",
      "                            └── Value: 1.0\n",
      "                                └── Leaf: 0.0\n",
      "            ├── Value: 2.0\n",
      "                └── Leaf: 0.0\n",
      "            ├── Value: 3.0\n",
      "                └── Leaf: 0.0\n",
      "            └── Value: 4.0\n",
      "                └── Leaf: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = 'c'\n",
    "features = data.columns[:-1]\n",
    "\n",
    "tree = ID3DecisionTree()\n",
    "tree.build_tree(data, features, target)\n",
    "\n",
    "tree.render_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ID3 Algorithm Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E</th>\n",
       "      <th>D</th>\n",
       "      <th>B</th>\n",
       "      <th>class</th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   E    D    B  class    A    C\n",
       "0  2  1.0  1.0    0.0  NaN  NaN\n",
       "1  2  0.0  NaN    1.0  NaN  NaN\n",
       "2  1  2.0  NaN    0.0  0.0  NaN\n",
       "3  2  0.0  NaN    1.0  NaN  NaN\n",
       "4  1  1.0  2.0    1.0  NaN  0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoints = tree.generate_data(10)\n",
    "datapoints.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp0-Eg875FwU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
