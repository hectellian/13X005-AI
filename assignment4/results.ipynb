{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4 - AI : \n",
    "---\n",
    "_Author: CHRISTOFOROU Anthony_\\\n",
    "_Due Date: XX-XX-2023_\\\n",
    "_Updated: 29-11-2023_\\\n",
    "_Description: TP4 - AI_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Modules\n",
    "from assignment4.utils import (entropy, information_gain, gini_index, accuracy, precision, recall, f1, render_scores)\n",
    "from assignment4.algorithms.decision_trees.id3 import ID3DecisionTree\n",
    "\n",
    "# make figures appear inline\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 8)\n",
    "%matplotlib inline\n",
    "\n",
    "# notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entropy and Information Gain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Depedent Variable Entropy\n",
    "\n",
    "The first step in building a decision tree is to calculate the entropy of the dependent variable. The entropy of the dependent variable is also known as the class entropy.\n",
    "\n",
    "<div class='alert alert-info'>\n",
    "But what is even Entropy?\n",
    "</div>\n",
    "\n",
    "Entropy is a measure of the amount of uncertainty or randomness in data.\n",
    "To calculate the entropy of the dependent variable, we need to determine the frequency of each class in the target variable and then use the entropy formula:\n",
    "\n",
    "$$Entropy(S) = -\\sum_{i=1}^{c}p_i\\log_2(p_i)$$\n",
    "\n",
    "where $p_i$ is the proportion of the number of elements in class $i$ to the number of elements in set $S$.\n",
    "\n",
    "<div class='alert alert-info'>\n",
    "So how do we do this, and how do we now which one is the dependent variable?\n",
    "</div>\n",
    "\n",
    "Let's start by loading the CSV data and find the dependent variable. We we then use the formula and calculate the entropy.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D  E  c\n",
       "0  0  1  3  1  1  0\n",
       "1  0  1  2  1  2  0\n",
       "2  0  0  3  4  0  1\n",
       "3  0  1  1  3  1  0\n",
       "4  0  0  1  3  0  1"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'data/data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has five independent variables (A, B, C, D, E) and one dependent variable (c). The next step is to calculate the entropy of the said dependent variable.\n",
    "\n",
    "Let's calculate the entropy of 'c'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculates Entropy: 0.974\n"
     ]
    }
   ],
   "source": [
    "entropy = entropy(data, 'c')\n",
    "print(f\"Calculates Entropy: {entropy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entropy of the dependent variable `'c'` in the dataset is approximately `0.974`. This value represents the amount of uncertainty or randomness in the distribution of class labels in the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Information Gain after Random Decision Criteria Application "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will calculate the information gain after applying three random decision criteria. For this, we need to:\n",
    "\n",
    "1. Select three random features (criteria) from the independent variables.\n",
    "2. For each feature, split the dataset based on its unique values.\n",
    "3. Calculate the entropy for each split.\n",
    "4. Compute the information gain for each feature.\n",
    "\n",
    "<div class='alert alert-info'>\n",
    "We will select three features randomly from the dataset and calculate their information gain. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information gain for C: 0.013\n",
      "Information gain for A: 0.029\n",
      "Information gain for E: 0.257\n"
     ]
    }
   ],
   "source": [
    "# Select three random features from the independent variables\n",
    "random_features = np.random.choice(['A', 'B', 'C', 'D', 'E'], 3, replace=False)\n",
    "\n",
    "# Calculate the information gain for each of these features\n",
    "information_gains = {feature: information_gain(data, feature, 'c') for feature in random_features}\n",
    "for feature, gain in information_gains.items():\n",
    "    print(f\"Information gain for {feature}: {gain:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "These values indicate how much each feature reduces the uncertainty about the class labels. A higher information gain implies a greater reduction in uncertainty.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Gini Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will calculate the Gini index for the same three features. The Gini index is calculated as:\n",
    "\n",
    "$$Gini(S) = 1 - \\sum_{i=1}^{c}p_i^2$$\n",
    "\n",
    "where $p_i$ is the proportion of the number of elements in class $i$ to the number of elements in set $S$.\n",
    "\n",
    "Let's proceed with calculating the Gini index for the random features,\n",
    "the Gini index should be a value between 0 and 1, where 0 indicates perfect purity (all elements in a subset belong to the same class) and 1 indicates maximal impurity (elements are evenly distributed across different classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini index for C: 0.473\n",
      "Gini index for A: 0.463\n",
      "Gini index for E: 0.318\n"
     ]
    }
   ],
   "source": [
    "gini_indices = {feature: gini_index(data, feature, 'c') for feature in random_features}\n",
    "for feature, gain in gini_indices.items():\n",
    "    print(f\"Gini index for {feature}: {gain:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gini index measures the impurity of a dataset after a split. A lower Gini index indicates a better split, as it implies a higher purity of the subsets created by the split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Best Decision Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best feature by Information Gain: E with gain 0.257\n",
      "Best feature by Gini Index: E with index 0.318\n"
     ]
    }
   ],
   "source": [
    "best_feature_info_gain = max(information_gains, key=information_gains.get)\n",
    "print(f\"Best feature by Information Gain: {best_feature_info_gain} with gain {information_gains[best_feature_info_gain]:.3f}\")\n",
    "\n",
    "best_feature_gini_index = min(gini_indices, key=gini_indices.get)\n",
    "print(f\"Best feature by Gini Index: {best_feature_gini_index} with index {gini_indices[best_feature_gini_index]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see:\n",
    "- A high Information Gain suggests the most informative for predicting the dependent variable `'c'`.\n",
    "- A low Gini index appears to be the most effective at reducing impurity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ID3 Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. ID3 Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n",
      "├── Value: 0\n",
      "│   └── C\n",
      "│       ├── Value: 0\n",
      "│       │   └── Leaf: False\n",
      "│       ├── Value: 1\n",
      "│       │   └── Leaf: True\n",
      "│       ├── Value: 2\n",
      "│       │   └── A\n",
      "│       │       ├── Value: 0\n",
      "│       │       │   └── Leaf: True\n",
      "│       │       └── Value: 1\n",
      "│       │           └── B\n",
      "│       │               ├── Value: 0\n",
      "│       │               │   └── Leaf: False\n",
      "│       │               └── Value: 1\n",
      "│       │                   └── Leaf: True\n",
      "│       └── Value: 3\n",
      "│           └── Leaf: True\n",
      "├── Value: 1\n",
      "│   └── D\n",
      "│       ├── Value: 0\n",
      "│       │   └── A\n",
      "│       │       ├── Value: 1\n",
      "│       │       │   └── Leaf: False\n",
      "│       │       └── Value: 2\n",
      "│       │           └── Leaf: True\n",
      "│       ├── Value: 1\n",
      "│       │   └── C\n",
      "│       │       ├── Value: 0\n",
      "│       │       │   └── Leaf: True\n",
      "│       │       ├── Value: 1\n",
      "│       │       │   └── Leaf: False\n",
      "│       │       ├── Value: 2\n",
      "│       │       │   └── B\n",
      "│       │       │       ├── Value: 0\n",
      "│       │       │       │   └── Leaf: True\n",
      "│       │       │       └── Value: 1\n",
      "│       │       │           └── Leaf: False\n",
      "│       │       └── Value: 3\n",
      "│       │           └── Leaf: False\n",
      "│       ├── Value: 2\n",
      "│       │   └── A\n",
      "│       │       ├── Value: 0\n",
      "│       │       │   └── Leaf: False\n",
      "│       │       └── Value: 2\n",
      "│       │           └── B\n",
      "│       │               ├── Value: 0\n",
      "│       │               │   └── Leaf: True\n",
      "│       │               └── Value: 1\n",
      "│       │                   └── Leaf: False\n",
      "│       ├── Value: 3\n",
      "│       │   └── Leaf: False\n",
      "│       └── Value: 4\n",
      "│           └── Leaf: False\n",
      "└── Value: 2\n",
      "    └── D\n",
      "        ├── Value: 0\n",
      "        │   └── Leaf: True\n",
      "        ├── Value: 1\n",
      "        │   └── B\n",
      "        │       ├── Value: 0\n",
      "        │       │   └── Leaf: True\n",
      "        │       ├── Value: 1\n",
      "        │       │   └── Leaf: False\n",
      "        │       └── Value: 2\n",
      "        │           └── C\n",
      "        │               ├── Value: 0\n",
      "        │               │   └── Leaf: True\n",
      "        │               └── Value: 1\n",
      "        │                   └── Leaf: False\n",
      "        ├── Value: 2\n",
      "        │   └── Leaf: False\n",
      "        ├── Value: 3\n",
      "        │   └── Leaf: False\n",
      "        └── Value: 4\n",
      "            └── Leaf: False\n",
      "Node(attribute=E, children={0: Node(attribute=C, children={0: 0, 1: 1, 2: Node(attribute=A, children={0: 1, 1: Node(attribute=B, children={0: 0, 1: 1})}), 3: 1}), 1: Node(attribute=D, children={0: Node(attribute=A, children={1: 0, 2: 1}), 1: Node(attribute=C, children={0: 1, 1: 0, 2: Node(attribute=B, children={0: 1, 1: 0}), 3: 0}), 2: Node(attribute=A, children={0: 0, 2: Node(attribute=B, children={0: 1, 1: 0})}), 3: 0, 4: 0}), 2: Node(attribute=D, children={0: 1, 1: Node(attribute=B, children={0: 1, 1: 0, 2: Node(attribute=C, children={0: 1, 1: 0})}), 2: 0, 3: 0, 4: 0})})\n"
     ]
    }
   ],
   "source": [
    "target = 'c'\n",
    "features = data.columns[:-1]\n",
    "\n",
    "tree = ID3DecisionTree(use_gini=True)\n",
    "tree.build_tree(data, features, target)\n",
    "\n",
    "tree.render_tree()\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ID3 Algorithm Data Generation Procedure\n",
    "\n",
    "Let's generate data using the tree we created in the previous section. We will use the `predict()` function to predict the class label for each data point in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "195    0\n",
       "196    1\n",
       "197    1\n",
       "198    1\n",
       "199    0\n",
       "Name: c, Length: 200, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = tree.predict(data)\n",
    "\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the generated data points are classified correctly by the decision tree (match the class labels in the tree) because the decision tree is trained on that same data. So we need to use a different dataset to test the performance of the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Forest of Decision Trees with Majority Vote\n",
    "\n",
    "Using the information gain criterion, we will build 5 decision trees using random samples of 80% of the data. We will use as prediction, a majority vote of the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(forest: list[ID3DecisionTree], test_data: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Predict the majority vote for a given test dataset using a forest of decision trees.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forest : list\n",
    "        A list of decision trees.\n",
    "    test_data : pandas.DataFrame\n",
    "        The test dataset.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.Series\n",
    "        The majority vote for each row in the test dataset.\n",
    "    \"\"\"\n",
    "    predictions = [forest_tree.predict(test_data) for forest_tree in forest]\n",
    "\n",
    "    # Combine predictions and decide based on majority vote\n",
    "    predictions_df = pd.DataFrame(predictions).T\n",
    "    majority_votes = predictions_df.mode(axis=1)[0]  # [0] to select the first mode in case of ties\n",
    "\n",
    "    return majority_votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict the class label for each data point in the test dataset using the forest of decision trees we created in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      0\n",
      "4      1\n",
      "      ..\n",
      "195    0\n",
      "196    1\n",
      "197    1\n",
      "198    0\n",
      "199    0\n",
      "Name: 0, Length: 200, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "forest: list[ID3DecisionTree] = []\n",
    "sample_size = 0.8\n",
    "\n",
    "for i in range(5):\n",
    "    sample_data = data.sample(frac=sample_size, replace=True)\n",
    "    forest_tree = ID3DecisionTree()\n",
    "    forest_tree.build_tree(sample_data, features, target)\n",
    "    forest.append(forest_tree)\n",
    "    \n",
    "test_data_path = 'data/data_test.csv'\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "forest_predictions = majority_vote(forest, test_data)\n",
    "\n",
    "print(f\"Predictions:\\n{forest_predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Evaluation of Tree-Based Models\n",
    "\n",
    "In this section, we delve into the assessment of our initial decision tree and compare its effectiveness with that of a random forest. The evaluation metrics include accuracy, precision, recall, and the F1 score. Each of these metrics offers a unique perspective on the performance of the models.\n",
    "\n",
    "#### 2.5.1. Accuracy\n",
    "\n",
    "Accuracy represents the proportion of all predictions that were correct. It's a straightforward measure of how often the model predicts correctly, irrespective of the prediction type.\n",
    "\n",
    "$$Accuracy = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}$$\n",
    "\n",
    "Here, \\( TP \\) and \\( TN \\) represent true positives and true negatives, respectively, while \\( FP \\) and \\( FN \\) denote false positives and false negatives.\n",
    "\n",
    "#### 2.5.2. Precision\n",
    "\n",
    "Precision, also known as Positive Predictive Value, quantifies the accuracy of positive predictions. It shows the fraction of positive predictions that were actually correct.\n",
    "\n",
    "$$Precision = \\frac{\\text{True Positives}}{\\text{Total Predicted Positives}}$$\n",
    "\n",
    "#### 2.5.3. Recall\n",
    "\n",
    "Recall, or Sensitivity, measures the model's ability to correctly identify all relevant instances. Specifically, it's the proportion of actual positives that were correctly identified.\n",
    "\n",
    "$$Recall = \\frac{\\text{True Positives}}{\\text{Total Actual Positives}}$$\n",
    "\n",
    "#### 2.5.4. F1 Score\n",
    "\n",
    "The F1 score is a balanced measure that combines precision and recall. It is particularly useful when the distribution of the classes is imbalanced.\n",
    "\n",
    "$$F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}$$\n",
    "\n",
    "By using these metrics, we can thoroughly evaluate and compare the performance of the decision tree and the forest of decision trees, providing a comprehensive understanding of their strengths and weaknesses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .score-table {\n",
       "            width: 60%;\n",
       "            margin-left: auto;\n",
       "            margin-right: auto;\n",
       "            border-collapse: collapse;\n",
       "            text-align: center;\n",
       "        }\n",
       "        .score-table th, .score-table td {\n",
       "            border: 1px solid #dddddd;\n",
       "            padding: 8px;\n",
       "        }\n",
       "        .score-table th {\n",
       "            background-color: #16537e;\n",
       "        }\n",
       "    </style>\n",
       "    <table class=\"score-table\">\n",
       "        <tr>\n",
       "            <th>Metric</th>\n",
       "            <th>Decision Tree</th>\n",
       "            <th>Random Forest</th>\n",
       "        </tr>\n",
       "    <tr><td>Accuracy</td><td>0.785</td><td>0.760</td></tr><tr><td>Precision</td><td>0.935</td><td>0.931</td></tr><tr><td>Recall</td><td>0.699</td><td>0.659</td></tr><tr><td>F1</td><td>0.800</td><td>0.771</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree_predictions = tree.predict(test_data)\n",
    "\n",
    "tree_scores = {\n",
    "    'Accuracy': accuracy(tree_predictions, test_data['c']),\n",
    "    'Precision': precision(tree_predictions, test_data['c']),\n",
    "    'Recall': recall(tree_predictions, test_data['c']),\n",
    "    'F1': f1(tree_predictions, test_data['c'])\n",
    "}\n",
    "\n",
    "forest_scores = {\n",
    "    'Accuracy': accuracy(forest_predictions, test_data['c']),\n",
    "    'Precision': precision(forest_predictions, test_data['c']),\n",
    "    'Recall': recall(forest_predictions, test_data['c']),\n",
    "    'F1': f1(forest_predictions, test_data['c'])\n",
    "}\n",
    "\n",
    "render_scores(tree_scores, forest_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Decision Tree Results Analysis\n",
    "\n",
    "1. **Accuracy:** The decision tree has an accuracy of around ~0.79, while the random forest has an accuracy of ~0.76. This means that the decision tree correctly makes predictions in 79% of cases, compared to 76% for the random forest. In this aspect, the decision tree is slightly better.\n",
    "\n",
    "2. **Precision:** Precision is very high for both models, with 0.94 for both the decision tree and the random forest. This indicates that when they predict a positive class, they are usually correct.\n",
    "\n",
    "3. **Recall:** The recall is higher for the decision tree (0.699~0.700) than for the random forest (0.64~0.66). This means that the decision tree is better at detecting positive instances.\n",
    "\n",
    "4. **F1 Score:** The F1 score, which is the harmonic mean of precision and recall, is also higher for the decision tree (~0.80) than for the random forest (~0.77). This score is particularly important in situations where a balance between precision and recall is crucial.\n",
    "\n",
    "#### Conclusion on Model Choice using the F1 Score\n",
    "\n",
    "Based on the F1 score, the decision tree should be preferred. Although its accuracy is only slightly better than that of the random forest, its ability to balance precision and recall, as evidenced by its higher F1 score, makes it more suitable, especially in contexts where it's important to maintain a good balance between detecting positive instances (recall) and minimizing false positives (precision)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp0-Eg875FwU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
